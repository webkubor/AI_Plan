#### 基础设施层：AI 的 “硬件底座”

这是支撑 AI 运行的物理基础，决定了模型训练和推理的效率与成本。

- **算力**：以 GPU（NVIDIA A100/H100）、TPU（谷歌张量处理单元）为核心，是大规模模型训练的核心资源，云厂商（AWS、阿里云、腾讯云）提供的 AI 算力服务是中小团队的主流选择。
- **存储**：用于存储海量训练数据和模型参数，需要高吞吐、低延迟的分布式存储系统，如对象存储（S3、OSS）、分布式文件系统（HDFS）。
- **网络**：高速互联网络，保障分布式训练时多个计算节点间的数据传输效率，如 RDMA 网络。

#### 核心模型层：AI 的 “智能引擎”

| **LLM（大语言模型）**     | 自然语言理解、生成、推理         | GPT-4、Claude 3、Llama 3、通义千问 | 智能客服、代码生成、文档撰写                 |
| ------------------------- | -------------------------------- | ---------------------------------- | -------------------------------------------- |
| **CV（计算机视觉）模型**  | 图像识别、分割、生成             | ViT、Stable Diffusion、DALL·E 3    | UI 设计生成、图片验证码识别、界面截图分析    |
| **多模态模型**            | 融合文本、图像、语音等多类型数据 | GPT-4V、Gemini、通义千问多模态     | 设计稿转代码、图文并茂的文档生成             |
| **Embedding（嵌入）模型** | 将非结构化数据转为向量           | text-embedding-3、m3e、bge-large   | 前端组件检索、用户行为语义分析、支付意图识别 |
| **语音模型**              | 语音识别（ASR）、语音合成（TTS） | Whisper、讯飞星火语音模型          | 语音支付、语音客服交互                       |

#### 开发框架层：AI 的 “开发工具链”

用于简化模型训练、推理和部署的工具集合，降低 AI 开发门槛。

- **训练框架**：用于构建和训练模型，如 PyTorch、TensorFlow、JAX，是 AI 研究员和算法工程师的核心工具。

- **推理框架**：优化模型在生产环境的运行效率，如 ONNX Runtime、TensorRT、vLLM，能大幅提升模型响应速度，降低部署成本。

- **应用开发框架**：面向业务开发者的封装工具，让前端 / 后端工程师无需深入算法即可集成 AI 能力，如 LangChain.js（前端 LLM 应用开发）、LlamaIndex（数据检索增强生成）。

- #### 数据层：AI 的 “燃料”

  数据是模型训练的基础，决定了模型的能力上限。

  - **训练数据**：海量、高质量的结构化 / 非结构化数据，如文本、图像、语音，需要经过清洗、标注等预处理才能用于训练。
  - **领域数据**：针对特定行业的垂直数据，如支付领域的交易文本、报错日志、用户咨询记录，基于领域数据微调的模型能更精准地解决行业问题。
  - **向量数据库**：专门用于存储 Embedding 向量的数据库，如 Pinecone、Milvus、Weaviate，支持高效的语义检索，是实现 AI 记忆、个性化推荐的核心组件。

  ### 前端视角下的基础层应用重点

  作为前端工程师，无需深入掌握模型训练和底层框架，但需要重点关注以下基础层组件的应用：

  1. **LLM API**：通过调用 OpenAI、通义千问等厂商的 API，快速在前端项目中集成对话、生成等 AI 功能；
  2. **Embedding 模型**：用于实现前端组件的语义检索、用户行为分析，如 “根据用户输入的需求，自动匹配最合适的 UI 组件”；
  3. **向量数据库**：结合 Embedding 模型，实现前端应用的个性化推荐、历史对话记忆等功能；
  4. **前端友好的开发框架**：如 LangChain.js，让你能快速构建 AI 工作流和 Agent 应用。